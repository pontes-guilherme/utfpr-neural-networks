{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "import math\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \n",
    "    _weights = []\n",
    "    _output_neurons = 1\n",
    "    \n",
    "    def __init__(self, eta=0.1, epochs=1000):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def set_output_neurons(self, n):\n",
    "        self._output_neurons = n\n",
    "    \n",
    "    def init_weights(self, size):\n",
    "        self._weights = []\n",
    "        for _ in range(self._output_neurons):\n",
    "            self_weights.append([1] + [random.uniform(-1, 1) for _ in range(size)])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.set_output_neurons(len(y[0]))\n",
    "        self.init_weights(len(X[0]))\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            for x_row, y_row in zip(X, y):\n",
    "                \n",
    "                #lista de predições\n",
    "                #cada item refere-se à um neurônio de saída\n",
    "                y_pred_list = self.predict(x_row)\n",
    "                \n",
    "                #lista de erros\n",
    "                #cada item refere-se ao erro referente à um neutônio de saída\n",
    "                errors = []\n",
    "                for idx in enumerate(y_pred_list):\n",
    "                    y_pred = y_pred_list[idx]\n",
    "                    \n",
    "                    errors.append(y_d - y_pred)\n",
    "                \n",
    "                self._weights[0] += error*self.eta\n",
    "                \n",
    "                #self._weights[1:] = [w + (self.eta*error*x_i) for w, x_i in zip(self._weights[1:], x_row)] \n",
    "                for j in range(self._output_neurons):\n",
    "                    for i, w in enumerate(self._weights[1:]):\n",
    "                        self._weights[j][i+1] = w + (self.eta*error*x_row[i])\n",
    "                \n",
    "\n",
    "    def predict(self, x_row):\n",
    "        s = self._weights[0]\n",
    "        \n",
    "        for x_i, w in zip(x_row, self._weights[1:]):\n",
    "            s += x_i * w\n",
    "        \n",
    "        return self.activate(s)\n",
    "        \n",
    "    def activate(self, prediction):\n",
    "        return 1 if prediction > 0 else -1\n",
    "    \n",
    "    \n",
    "class Adaline(Perceptron):\n",
    "    def __init__(self, eta=0.1, epochs=100):\n",
    "        super().__init__(eta, epochs)\n",
    "        \n",
    "    def activate(self, prediction):\n",
    "        return prediction\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.19999999999999932, 0.24531650125855312, 0.14132082547812774]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = [\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [1,0],\n",
    "    [1,1],\n",
    "]\n",
    "\n",
    "y = [\n",
    "    [0,0],\n",
    "    [0,1],\n",
    "    [0,1],\n",
    "    [1,1],\n",
    "]\n",
    "\n",
    "#y_train_and = [0, 0, 0, 1]\n",
    "#y_train_or = [0, 1, 1, 1]\n",
    "\n",
    "\n",
    "perceptron = Perceptron()\n",
    "#perceptron.fit(x_train, y_train_and)\n",
    "perceptron.fit(x_train, y)\n",
    "\n",
    "perceptron._weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.predict([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5cf3866351ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0madaline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0madaline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# data = [(x,x*x) for x in range (-10, 10)]\n",
    "\n",
    "# x = [[x] for x,y in data]\n",
    "# y = [y for x,y in data]\n",
    "\n",
    "\n",
    "\n",
    "adaline = Adaline()\n",
    "\n",
    "adaline.fit(x, y)\n",
    "\n",
    "print('X: ', x)\n",
    "print('y: ', y)\n",
    "print(adaline._weights)\n",
    "\n",
    "adaline.predict([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _TRAIN_SIZE = 0.7\n",
    "\n",
    "# iris = load_iris()\n",
    "# data = iris.data\n",
    "\n",
    "\n",
    "# tuple_data = [(x,y) for x,y in zip(iris.data, iris.target)]\n",
    "# tuple_data = [item for item in tuple_data if item[1] != 2]\n",
    "\n",
    "# random.shuffle(tuple_data)\n",
    "\n",
    "# split_point = int(len(tuple_data)*_TRAIN_SIZE)\n",
    "# training_data, test_data = tuple_data[:split_point], tuple_data[split_point+1:]\n",
    "\n",
    "# x_train = [x for x,y in training_data]\n",
    "# y_train = [y for x,y in training_data]\n",
    "\n",
    "# x_test = [x for x,y in test_data]\n",
    "# y_test = [y for x,y in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
